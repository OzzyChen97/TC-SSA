{"_id":"672c52036f6797b2887ab13e","id":"General-Medical-AI/SlideChat","author":"General-Medical-AI","sha":"516bb3239b6da295ff1477ebfb3779fb4ddf16c8","lastModified":"2025-08-04T07:01:43.000Z","private":false,"gated":false,"disabled":false,"tags":["size_categories:100K<n<1M","format:json","modality:text","library:datasets","library:dask","library:mlcroissant","arxiv:2410.11761","region:us"],"citation":null,"description":"\n\t\n\t\t\n\t\tIntroduction\n\t\n\nWe present SlideChat, the first open-source vision-language assistant capable of understanding gigapixel whole-slide images. To systematic0ally evaluate the performance of SlideChat, we developed SlideBench, a comprehensive benchmark comprising three components: SlideBench-Caption, SlideBench-VQA (TCGA), and SlideBench-VQA (BCNB).\n\nSlideBench-Caption: This test set includes 734 WSIs from the TCGA dataset, providing a foundation to evaluate SlideChat's proficiency inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/General-Medical-AI/SlideChat.","downloads":327,"likes":12,"cardData":null,"siblings":[{"rfilename":".gitattributes"},{"rfilename":"Feat/BCNB_patch_feat.tar.gz"},{"rfilename":"Feat/TCGA_ACC_feat_conch.tar.gz"},{"rfilename":"README.md"},{"rfilename":"SlideBench-Caption-CPTAC.csv"},{"rfilename":"SlideBench-Caption-TCGA-plus.csv"},{"rfilename":"SlideBench-Caption-TCGA.csv"},{"rfilename":"SlideBench-VQA-BCNB.csv"},{"rfilename":"SlideBench-VQA-CPTAC.csv"},{"rfilename":"SlideBench-VQA-TCGA-plus.csv"},{"rfilename":"SlideBench-VQA-TCGA.csv"},{"rfilename":"SlideInstruct_train_stage1_caption.json"},{"rfilename":"SlideInstruct_train_stage2_vqa.json"}],"createdAt":"2024-11-07T05:37:07.000Z","usedStorage":7934304989}