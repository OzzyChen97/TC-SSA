"""
æŒ‰ç…§ 8:1:1 æ¯”ä¾‹å°† tcga_brca_dataset.csv åˆ†å‰²ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚
"""

import pandas as pd
import numpy as np
from pathlib import Path

# ================= é…ç½®åŒºåŸŸ =================
# è¾“å…¥æ–‡ä»¶
INPUT_CSV = '/workspace/ETC/tcga_brca_dataset.csv'

# è¾“å‡ºç›®å½•
OUTPUT_DIR = '/workspace/ETC/dataset'

# åˆ†å‰²æ¯”ä¾‹ (train:val:test = 8:1:1)
TRAIN_RATIO = 0.8
VAL_RATIO = 0.1
TEST_RATIO = 0.1

# éšæœºç§å­ï¼ˆä¿è¯å¯é‡å¤æ€§ï¼‰
RANDOM_SEED = 42
# ===========================================


def split_dataset():
    """æŒ‰ç…§æŒ‡å®šæ¯”ä¾‹åˆ†å‰²æ•°æ®é›†ï¼Œå¹¶ä¿æŒç±»åˆ«å¹³è¡¡"""

    print("=" * 50)
    print("TCGA BRCA æ•°æ®é›†åˆ†å‰²è„šæœ¬")
    print("=" * 50)
    print(f"è¾“å…¥æ–‡ä»¶: {INPUT_CSV}")
    print(f"è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print(f"åˆ†å‰²æ¯”ä¾‹: Train={TRAIN_RATIO:.1%}, Val={VAL_RATIO:.1%}, Test={TEST_RATIO:.1%}")
    print(f"éšæœºç§å­: {RANDOM_SEED}")
    print("=" * 50)
    print()

    # 1. è¯»å–æ•°æ®é›†
    print("æ­£åœ¨è¯»å–æ•°æ®é›†...")
    df = pd.read_csv(INPUT_CSV)
    print(f"âœ“ åŠ è½½å®Œæˆ: {len(df)} ä¸ªæ ·æœ¬")

    # 2. æŸ¥çœ‹ç±»åˆ«åˆ†å¸ƒ
    print("\nåŸå§‹æ•°æ®é›†ç±»åˆ«åˆ†å¸ƒ:")
    class_counts = df['label'].value_counts().sort_index()
    for label, count in class_counts.items():
        label_name = "IDC (æµ¸æ¶¦æ€§å¯¼ç®¡ç™Œ)" if label == 0 else "ILC (æµ¸æ¶¦æ€§å°å¶ç™Œ)"
        print(f"  Class {label} ({label_name}): {count} æ ·æœ¬ ({count/len(df)*100:.1f}%)")
    print()

    # 3. è®¾ç½®éšæœºç§å­
    np.random.seed(RANDOM_SEED)

    # 4. æ‰‹åŠ¨å®ç°åˆ†å±‚æŠ½æ ·åˆ†å‰²
    print("æ­£åœ¨è¿›è¡Œæ•°æ®é›†åˆ†å‰²ï¼ˆä¿æŒç±»åˆ«æ¯”ä¾‹ï¼‰...")

    train_dfs = []
    val_dfs = []
    test_dfs = []

    # å¯¹æ¯ä¸ªç±»åˆ«åˆ†åˆ«è¿›è¡Œåˆ†å‰²
    for label in df['label'].unique():
        # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰æ ·æœ¬
        class_df = df[df['label'] == label].copy()
        n_samples = len(class_df)

        # æ‰“ä¹±é¡ºåº
        class_df = class_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)

        # è®¡ç®—å„éƒ¨åˆ†çš„æ ·æœ¬æ•°
        n_train = int(n_samples * TRAIN_RATIO)
        n_val = int(n_samples * VAL_RATIO)
        # test å–å‰©ä½™çš„ï¼Œé¿å…èˆå…¥è¯¯å·®

        # åˆ†å‰²
        train_dfs.append(class_df[:n_train])
        val_dfs.append(class_df[n_train:n_train + n_val])
        test_dfs.append(class_df[n_train + n_val:])

    # åˆå¹¶å„ç±»åˆ«çš„åˆ†å‰²ç»“æœ
    train_df = pd.concat(train_dfs, ignore_index=True)
    val_df = pd.concat(val_dfs, ignore_index=True)
    test_df = pd.concat(test_dfs, ignore_index=True)

    # å†æ¬¡æ‰“ä¹±ï¼ˆå¯é€‰ï¼Œä½¿ä¸åŒç±»åˆ«æ··åˆï¼‰
    train_df = train_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)
    val_df = val_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)
    test_df = test_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)

    print("âœ“ åˆ†å‰²å®Œæˆï¼")
    print()

    # 6. æ‰“å°åˆ†å‰²åçš„ç»Ÿè®¡ä¿¡æ¯
    print("=" * 50)
    print("åˆ†å‰²åå„æ•°æ®é›†ç»Ÿè®¡:")
    print("=" * 50)

    for split_name, split_df in [
        ("è®­ç»ƒé›† (Train)", train_df),
        ("éªŒè¯é›† (Val)", val_df),
        ("æµ‹è¯•é›† (Test)", test_df)
    ]:
        print(f"\n{split_name}:")
        print(f"  æ€»æ ·æœ¬æ•°: {len(split_df)} ({len(split_df)/len(df)*100:.1f}%)")
        print(f"  ç±»åˆ«åˆ†å¸ƒ:")

        for label in sorted(split_df['label'].unique()):
            count = (split_df['label'] == label).sum()
            label_name = "IDC (æµ¸æ¶¦æ€§å¯¼ç®¡ç™Œ)" if label == 0 else "ILC (æµ¸æ¶¦æ€§å°å¶ç™Œ)"
            print(f"    Class {label} ({label_name}): {count} æ ·æœ¬ ({count/len(split_df)*100:.1f}%)")

    print()
    print("=" * 50)

    # 7. åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(OUTPUT_DIR)
    output_path.mkdir(parents=True, exist_ok=True)

    # 8. ä¿å­˜åˆ†å‰²åçš„æ•°æ®é›†
    print("\næ­£åœ¨ä¿å­˜åˆ†å‰²åçš„CSVæ–‡ä»¶...")

    train_path = output_path / 'train.csv'
    val_path = output_path / 'val.csv'
    test_path = output_path / 'test.csv'

    train_df.to_csv(train_path, index=False)
    val_df.to_csv(val_path, index=False)
    test_df.to_csv(test_path, index=False)

    print(f"âœ“ è®­ç»ƒé›†å·²ä¿å­˜: {train_path} ({len(train_df)} æ ·æœ¬)")
    print(f"âœ“ éªŒè¯é›†å·²ä¿å­˜: {val_path} ({len(val_df)} æ ·æœ¬)")
    print(f"âœ“ æµ‹è¯•é›†å·²ä¿å­˜: {test_path} ({len(test_df)} æ ·æœ¬)")
    print()

    # 9. éªŒè¯åˆ†å‰²æ¯”ä¾‹
    print("=" * 50)
    print("åˆ†å‰²æ¯”ä¾‹éªŒè¯:")
    print("=" * 50)
    total = len(df)
    print(f"è®­ç»ƒé›†: {len(train_df)}/{total} = {len(train_df)/total:.1%} (ç›®æ ‡: {TRAIN_RATIO:.1%})")
    print(f"éªŒè¯é›†: {len(val_df)}/{total} = {len(val_df)/total:.1%} (ç›®æ ‡: {VAL_RATIO:.1%})")
    print(f"æµ‹è¯•é›†: {len(test_df)}/{total} = {len(test_df)/total:.1%} (ç›®æ ‡: {TEST_RATIO:.1%})")
    print()

    print("ğŸ‰ æ•°æ®é›†åˆ†å‰²å®Œæˆï¼å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼")
    print()


if __name__ == '__main__':
    split_dataset()
